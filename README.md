# statistical-learning-implementations
Collection of scratch implementation of statistical learning algorithms and techniques

## Description
### HW1 - Key takeaways
* Theoretical understanding and proofs of Bayes Learning concepts like error bounds, bayes network, decision boundaries, neymar pearson criterion
* Implementation and empirical analysis of central limit theorem to understand gaussian distribution well.

### HW2 - Key takeaways
* Theoretical understanding and proofs of Maxiumum Likelihood estimtion of poisson distribution, gamma distribution and concepts like conjugate prior.
* Implementation of PCA as dimensionality reduction on MNIST images and classifying using Fisher Linear Discriminant with training accuracy 94.25 and testing accuracy 81.0
* Implementation of Hidden Markov Model via Forward and viterbi algorithm
* Implementation of Gaussian process and plotting prior functions, mean estimate for non linear regression and posterior functions sampling the conditional gaussian distribution

### HW3 - Key takeaways
* Implementation of feed forward neural network on the MNIST image dataset
* Implementing softmax cross entropy loss functions,activation functions like sigmoid, relu, gradients per layer, dropout regularization
* Implementing forward pass, backward propagation module, momentum for optimization of gradient descent to obtain the traininga accuracy of 100% and testing accuracy of 90%
* Implementing mixed objective of semi supervised learning using labeled data for cross entropy loss and entropy loss for unlabeled data.
* Deriving derivative of mixed loss objective and implementing gradient check to validate the computation of loss gradients

###  HW4 - Key takeaways
* Implementation of Kmeans clustering on binomial data of 3 different coin tosses
* Implementation of Expected Maximization(EM) to determine the prior probabilities of 3 coins and probability of heads in each coin.
* Understanding the identifiability of solutions problem in EM by looking at the shuffling results of cluster heads for prior probabilities and head probabilities in different settings such as random initialization,initialization with the outcomes of KMeans algorithm
